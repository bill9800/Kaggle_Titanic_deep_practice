{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##import data\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "15           16         1       2   \n",
       "16           17         0       3   \n",
       "17           18         1       2   \n",
       "18           19         0       3   \n",
       "19           20         1       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                   Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                               Rice, Master. Eugene    male   2.0      4   \n",
       "17                       Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18  Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                            Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500   NaN        S  \n",
       "1       0          PC 17599  71.2833   C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3       0            113803  53.1000  C123        S  \n",
       "4       0            373450   8.0500   NaN        S  \n",
       "5       0            330877   8.4583   NaN        Q  \n",
       "6       0             17463  51.8625   E46        S  \n",
       "7       1            349909  21.0750   NaN        S  \n",
       "8       2            347742  11.1333   NaN        S  \n",
       "9       0            237736  30.0708   NaN        C  \n",
       "10      1           PP 9549  16.7000    G6        S  \n",
       "11      0            113783  26.5500  C103        S  \n",
       "12      0         A/5. 2151   8.0500   NaN        S  \n",
       "13      5            347082  31.2750   NaN        S  \n",
       "14      0            350406   7.8542   NaN        S  \n",
       "15      0            248706  16.0000   NaN        S  \n",
       "16      1            382652  29.1250   NaN        Q  \n",
       "17      0            244373  13.0000   NaN        S  \n",
       "18      0            345763  18.0000   NaN        S  \n",
       "19      0              2649   7.2250   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## observe data\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Cabin', 'Embarked'], dtype='object')\n",
      "Index(['Age', 'Fare', 'Cabin'], dtype='object')\n",
      "number of null in train Age\n",
      "177\n",
      "number of null in train Cabin\n",
      "687\n",
      "number of null in train Embarked\n",
      "2\n",
      "number of null in test Age\n",
      "86\n",
      "number of null in test Fare\n",
      "1\n",
      "number of null in test Cabin\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "full_data = [train,test]\n",
    "\n",
    "print(train.columns[train.isnull().any()])\n",
    "print(test.columns[test.isnull().any()])\n",
    "\n",
    "def num_null(dataset,train_or_test,col):\n",
    "    print(\"number of null in \"+train_or_test+\" \"+col)\n",
    "    print(dataset[col].isnull().sum())\n",
    "\n",
    "num_null(train,\"train\",'Age')\n",
    "num_null(train,\"train\",'Cabin')\n",
    "num_null(train,\"train\",'Embarked')\n",
    "num_null(test,\"test\",'Age')\n",
    "num_null(test,\"test\",'Fare')\n",
    "num_null(test,\"test\",'Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "full_data = [train,test]\n",
    "\n",
    "## label encoding\n",
    "for dataset in full_data:\n",
    "    dataset['Sex'] = le.fit_transform(dataset['Sex'])\n",
    "    # fill in missing Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "    dataset['Embarked'] = le.fit_transform(dataset['Embarked'])\n",
    "\n",
    "## create new feature\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Name_len = length of the name\n",
    "    dataset['Name_len'] = dataset['Name'].apply(len)\n",
    "    # Ticket_len = length of the ticket\n",
    "    dataset['Ticket_len'] = dataset['Ticket'].apply(len)\n",
    "    # Title = title in name\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # label encode title\n",
    "    dataset['Title'] = le.fit_transform(dataset['Title'])\n",
    "    \n",
    "## handle missing data\n",
    "# fill in missing 'Age'\n",
    "age_avg = train['Age'].mean()\n",
    "age_std = train['Age'].std()\n",
    "for dataset in full_data:\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    dataset['Age'][np.isnan(dataset['Age'])] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'][np.isnan(dataset['Fare'])] = train['Fare'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature selection\n",
    "\n",
    "drop_elements = ['PassengerId','Name','Ticket','Cabin']\n",
    "train = train.drop(drop_elements, axis=1)\n",
    "test = test.drop(drop_elements,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_len</th>\n",
       "      <th>Ticket_len</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>0.647587</td>\n",
       "      <td>29.653199</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>1.536476</td>\n",
       "      <td>26.965208</td>\n",
       "      <td>6.750842</td>\n",
       "      <td>1.895623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>0.477990</td>\n",
       "      <td>13.554461</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>0.791503</td>\n",
       "      <td>9.281607</td>\n",
       "      <td>2.745515</td>\n",
       "      <td>0.788465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Sex         Age       SibSp       Parch  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838    2.308642    0.647587   29.653199    0.523008    0.381594   \n",
       "std      0.486592    0.836071    0.477990   13.554461    1.102743    0.806057   \n",
       "min      0.000000    1.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    2.000000    0.000000   21.000000    0.000000    0.000000   \n",
       "50%      0.000000    3.000000    1.000000   28.000000    0.000000    0.000000   \n",
       "75%      1.000000    3.000000    1.000000   38.000000    1.000000    0.000000   \n",
       "max      1.000000    3.000000    1.000000   80.000000    8.000000    6.000000   \n",
       "\n",
       "             Fare    Embarked    Name_len  Ticket_len       Title  \n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000  \n",
       "mean    32.204208    1.536476   26.965208    6.750842    1.895623  \n",
       "std     49.693429    0.791503    9.281607    2.745515    0.788465  \n",
       "min      0.000000    0.000000   12.000000    3.000000    0.000000  \n",
       "25%      7.910400    1.000000   20.000000    5.000000    1.000000  \n",
       "50%     14.454200    2.000000   25.000000    6.000000    2.000000  \n",
       "75%     31.000000    2.000000   30.000000    7.000000    2.000000  \n",
       "max    512.329200    2.000000   82.000000   18.000000    4.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_len</th>\n",
       "      <th>Ticket_len</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  SibSp  Parch     Fare  Embarked  Name_len  \\\n",
       "0         0       3    1   22      1      0   7.2500         2        23   \n",
       "1         1       1    0   38      1      0  71.2833         0        51   \n",
       "2         1       3    0   26      0      0   7.9250         2        22   \n",
       "3         1       1    0   35      1      0  53.1000         2        44   \n",
       "4         0       3    1   35      0      0   8.0500         2        24   \n",
       "5         0       3    1   27      0      0   8.4583         1        16   \n",
       "6         0       1    1   54      0      0  51.8625         2        23   \n",
       "7         0       3    1    2      3      1  21.0750         2        30   \n",
       "8         1       3    0   27      0      2  11.1333         2        49   \n",
       "9         1       2    0   14      1      0  30.0708         0        35   \n",
       "\n",
       "   Ticket_len  Title  \n",
       "0           9      2  \n",
       "1           8      3  \n",
       "2          16      1  \n",
       "3           6      3  \n",
       "4           6      2  \n",
       "5           6      2  \n",
       "6           5      2  \n",
       "7           6      0  \n",
       "8           6      3  \n",
       "9           6      3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## normalize data \n",
    "full_data = [train,test]\n",
    "avg_age = train['Age'].mean()\n",
    "std_age = train['Age'].std()\n",
    "avg_fare = train['Fare'].mean()\n",
    "std_fare = train['Fare'].std()\n",
    "avg_name_len = train[\"Name_len\"].mean()\n",
    "avg_ticket_len = train['Ticket_len'].mean()\n",
    "for dataset in full_data:\n",
    "    dataset['Age'] = dataset['Age']-avg_age/std_age\n",
    "    dataset['Age'] = dataset['Age']/dataset['Age'].max()\n",
    "    dataset['Fare'] = dataset['Fare']-avg_fare/std_fare\n",
    "    dataset['Fare'] = dataset['Fare']/dataset['Age'].max()\n",
    "    dataset['Name_len'] = dataset['Name_len']/avg_name_len\n",
    "    dataset['Ticket_len'] = dataset['Ticket_len']/avg_ticket_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## split data\n",
    "X_train = train.drop('Survived',axis=1)\n",
    "Y_train = train['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is:  0.8154093097913323\n",
      "dev accuracy is: 0.8059701492537313\n"
     ]
    }
   ],
   "source": [
    "# try logistic regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "## split the data to 70/30\n",
    "train_X, dev_X, train_Y, dev_Y = train_test_split(X_train,Y_train,test_size=0.3)\n",
    "# train model\n",
    "lg = LogisticRegression()\n",
    "lg.fit(train_X,train_Y)\n",
    "# predict by logistic model\n",
    "train_predict_Y = lg.predict(train_X)\n",
    "# calculate the training accuracy\n",
    "train_accuracy = accuracy_score(train_Y,train_predict_Y)\n",
    "print(\"training accuracy is: \",train_accuracy)\n",
    "#calculate the develpment set accuracy\n",
    "dev_predict_Y = lg.predict(dev_X)\n",
    "dev_accuarcy = accuracy_score(dev_Y,dev_predict_Y)\n",
    "print(\"dev accuracy is:\",dev_accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy is:  0.8539325842696629\n",
      "dev accuracy is: 0.7350746268656716\n"
     ]
    }
   ],
   "source": [
    "#try SVM\n",
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_X,train_Y)  \n",
    "#predict by SVM\n",
    "train_predict_Y = clf.predict(train_X)\n",
    "# calculate the training accuracy\n",
    "train_accuracy = accuracy_score(train_Y,train_predict_Y)\n",
    "print(\"training accuracy is: \",train_accuracy)\n",
    "#calculate the develpment set accuracy\n",
    "dev_predict_Y = clf.predict(dev_X)\n",
    "dev_accuarcy = accuracy_score(dev_Y,dev_predict_Y)\n",
    "print(\"dev accuracy is:\",dev_accuarcy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## solve high bias problem first\n",
    "# create a shallow neural network\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x,n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \"\"\"\n",
    "    \n",
    "    X = tf.placeholder(tf.float32,shape=(n_x,None))\n",
    "    Y = tf.placeholder(tf.float32,shape=(n_y,None))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    W1 = tf.get_variable(\"W1\",[25,10],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(\"b1\",[25,1],initializer=tf.zeros_initializer())\n",
    "    W2 =  tf.get_variable(\"W2\",[15,25],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(\"b2\",[15,1],initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\",[2,15],initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(\"b3\",[2,1],initializer=tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                     \n",
    "    A1 = tf.nn.relu(Z1)                                             \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                           \n",
    "    A2 = tf.nn.relu(Z2)                                            \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                                             \n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute cost\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size, seed ):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    mini_batch_size -- size of the mini-batches, integer\n",
    "    \n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)            # To make your \"random\" minibatches the same as ours\n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((2,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:,k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[:,num_complete_minibatches:m]\n",
    "        mini_batch_Y = shuffled_Y[:,num_complete_minibatches:m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 16, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape \n",
    "    Y_train -- test set, of shape \n",
    "    X_test -- training set, of shape \n",
    "    Y_test -- test set, of shape \n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X,parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3,Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y)\n",
    "                _ , minibatch_cost = sess.run([optimizer,cost],feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
    "            \n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Dev Accuracy:\", accuracy.eval({X: X_dev, Y: Y_dev}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## transfer the data to apply the model\n",
    "train_X = train_X.values.T\n",
    "#train_Y = train_Y.values.reshape(1,623)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_X = dev_X.values.T\n",
    "#dev_Y = dev_Y.values.reshape(1,268)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_one_hot(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j) \n",
    "                     will be 1. \n",
    "                     \n",
    "    Arguments:\n",
    "    labels -- vector containing the labels \n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "    \n",
    "    Returns: \n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C)\n",
    "    \n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
    "    \n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "    \n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_deep_Y = convert_to_one_hot(train_Y,2)\n",
    "dev_deep_Y = convert_to_one_hot(dev_Y,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tune hyperparameter\n",
    "learning_rate_list = [1e-4,2e-4,3e-4,4e-4,5e-4,6e-4,7e-4,8e-4,9e-4,1e-3,3e-3,5e-3,7e-3,1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for learning_rate in learning_rate_list:\n",
    "#   parameters = model(train_X,train_Y,dev_X,dev_Y,learning_rate = learning_rate,num_epochs = 3000, minibatch_size = 32,print_cost = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-17-bbe7978c36aa>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "Cost after epoch 0: 1.946041\n",
      "Cost after epoch 100: 0.433737\n",
      "Cost after epoch 200: 0.412513\n",
      "Cost after epoch 300: 0.368334\n",
      "Cost after epoch 400: 0.366408\n",
      "Cost after epoch 500: 0.334033\n",
      "Cost after epoch 600: 0.333847\n",
      "Cost after epoch 700: 0.325836\n",
      "Cost after epoch 800: 0.324036\n",
      "Cost after epoch 900: 0.306675\n",
      "Cost after epoch 1000: 0.306901\n",
      "Cost after epoch 1100: 0.298140\n",
      "Cost after epoch 1200: 0.306412\n",
      "Cost after epoch 1300: 0.295475\n",
      "Cost after epoch 1400: 0.304452\n",
      "Cost after epoch 1500: 0.295169\n",
      "Cost after epoch 1600: 0.283053\n",
      "Cost after epoch 1700: 0.283201\n",
      "Cost after epoch 1800: 0.275455\n",
      "Cost after epoch 1900: 0.299605\n",
      "Cost after epoch 2000: 0.278340\n",
      "Cost after epoch 2100: 0.267726\n",
      "Cost after epoch 2200: 0.264564\n",
      "Cost after epoch 2300: 0.263018\n",
      "Cost after epoch 2400: 0.257573\n",
      "Cost after epoch 2500: 0.252022\n",
      "Cost after epoch 2600: 0.258588\n",
      "Cost after epoch 2700: 0.252372\n",
      "Cost after epoch 2800: 0.253764\n",
      "Cost after epoch 2900: 0.247746\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAETCAYAAADZHBoWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCTu/wMvxu6OvqHywwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xfd54251940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.882825\n",
      "Dev Accuracy: 0.76865673\n"
     ]
    }
   ],
   "source": [
    "parameters = model(train_X,train_deep_Y,dev_X,dev_deep_Y,learning_rate = 0.0005,num_epochs = 3000, minibatch_size = 32,print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_len</th>\n",
       "      <th>Ticket_len</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.430989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.181142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.593357</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.607112</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.351942</td>\n",
       "      <td>2</td>\n",
       "      <td>1.186714</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.039442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.927121</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336154</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.014442</td>\n",
       "      <td>2</td>\n",
       "      <td>0.593357</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.268415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.639442</td>\n",
       "      <td>2</td>\n",
       "      <td>1.631732</td>\n",
       "      <td>1.036908</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.576942</td>\n",
       "      <td>2</td>\n",
       "      <td>0.964205</td>\n",
       "      <td>0.592519</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.376798</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.981142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.741696</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.322606</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28.351942</td>\n",
       "      <td>2</td>\n",
       "      <td>1.038375</td>\n",
       "      <td>0.888778</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.214223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.581142</td>\n",
       "      <td>0</td>\n",
       "      <td>1.520478</td>\n",
       "      <td>0.592519</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.254867</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.501942</td>\n",
       "      <td>2</td>\n",
       "      <td>0.852951</td>\n",
       "      <td>1.333167</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch       Fare  Embarked  Name_len  \\\n",
       "0       3    1  0.430989      0      0   7.181142         1  0.593357   \n",
       "1       3    0  0.607112      1      0   6.351942         2  1.186714   \n",
       "2       2    1  0.810330      0      0   9.039442         1  0.927121   \n",
       "3       3    1  0.336154      0      0   8.014442         2  0.593357   \n",
       "4       3    0  0.268415      1      1  11.639442         2  1.631732   \n",
       "5       3    1  0.160032      0      0   8.576942         2  0.964205   \n",
       "6       3    0  0.376798      0      0   6.981142         1  0.741696   \n",
       "7       2    1  0.322606      1      1  28.351942         2  1.038375   \n",
       "8       3    0  0.214223      0      0   6.581142         0  1.520478   \n",
       "9       3    1  0.254867      2      0  23.501942         2  0.852951   \n",
       "\n",
       "   Ticket_len  Title  \n",
       "0    0.888778      2  \n",
       "1    0.888778      3  \n",
       "2    0.888778      2  \n",
       "3    0.888778      2  \n",
       "4    1.036908      3  \n",
       "5    0.592519      2  \n",
       "6    0.888778      1  \n",
       "7    0.888778      2  \n",
       "8    0.592519      3  \n",
       "9    1.333167      2  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert test data to submit\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test.values.T\n",
    "test_X = np.float32(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(test_X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_parameters(parameters):\n",
    "\n",
    "    W1 = tf.constant(parameters[\"W1\"],shape=[25,10])\n",
    "    b1 = tf.constant(parameters[\"b1\"],shape=[25,1])\n",
    "    W2 =  tf.constant(parameters[\"W2\"],shape=[15,25])\n",
    "    b2 = tf.constant(parameters[\"b2\"],shape=[15,1])\n",
    "    W3 = tf.constant(parameters[\"W3\"],shape=[2,15])\n",
    "    b3 = tf.constant(parameters[\"b3\"],shape=[2,1])\n",
    "    \n",
    "    model_parameters = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}\n",
    "    \n",
    "    return model_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(test_X, parameters):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = test_X.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = 2                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "\n",
    "    # Initialize parameters\n",
    "    model_parameters = input_parameters(parameters)\n",
    "    \n",
    "    #W1 = tf.constant(parameters[\"W1\"],shape=[25,10])\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(test_X,parameters)\n",
    "  \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # lets use the parameters we saved\n",
    "        sess.run(model_parameters)\n",
    "        #sess.run(W1)\n",
    "        \n",
    "        # Do prediction\n",
    "        softmax_result = tf.argmax(Z3)\n",
    "        \n",
    "        result = softmax_result.eval()\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict(test_X,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 0 0 0\n",
      " 1 0 0 1 0 0 1 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 0\n",
      " 1 1 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 0 0 1 0 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## prepare csv file to submit\n",
    "test_get_ID = pd.read_csv('test.csv')\n",
    "\n",
    "\n",
    "submit_dict = {\n",
    "   \"PassengerId\": test_get_ID[\"PassengerId\"],\n",
    "   \"Survived\": result\n",
    "}\n",
    "ouput = pd.DataFrame(submit_dict)\n",
    "# output the data\n",
    "ouput.to_csv(\"titanic_predict.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
